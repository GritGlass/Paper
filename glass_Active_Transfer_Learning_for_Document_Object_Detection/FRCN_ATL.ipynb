{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90fc2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "import time\n",
    "import utils_ObjectDetection as utils\n",
    "from torch.utils.data import BatchSampler,SequentialSampler,RandomSampler\n",
    "import torch.nn as nn\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import math \n",
    "from itertools import combinations\n",
    "import ITB_RECALL_PRECISION_F1 as rp_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e82ac59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, img, threshold):\n",
    "    model.eval()\n",
    "    preds = model(img)\n",
    "    for id in range(len(preds)) :\n",
    "        idx_list = []\n",
    "\n",
    "        for idx, score in enumerate(preds[id]['scores']) :\n",
    "            \n",
    "            if score > threshold : \n",
    "                idx_list.append(idx)\n",
    "\n",
    "        preds[id]['boxes'] = preds[id]['boxes'][idx_list]\n",
    "        preds[id]['labels'] = preds[id]['labels'][idx_list]\n",
    "        preds[id]['scores'] = preds[id]['scores'][idx_list]\n",
    "\n",
    "    return preds\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "def get_transform():\n",
    "    custom_transforms = []\n",
    "    custom_transforms.append(torchvision.transforms.ToTensor())\n",
    "    return torchvision.transforms.Compose(custom_transforms)\n",
    "\n",
    "\n",
    "def get_model_instance_segmentation(num_classes,train_layer):\n",
    "    # load an instance segmentation model pre-trained pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True,trainable_backbone_layers=train_layer)\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "def plot_image_from_output(img, annotation):\n",
    "    \n",
    "    img = img.cpu().permute(1,2,0)\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=(20, 10))\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    for idx in range(len(annotation[\"boxes\"])):\n",
    "        xmin, ymin, xmax, ymax = annotation[\"boxes\"][idx]\n",
    "\n",
    "        if annotation['labels'][idx] == 1 :\n",
    "            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='b',facecolor='none')\n",
    "        \n",
    "        elif annotation['labels'][idx] == 2 :\n",
    "            \n",
    "            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='g',facecolor='none')\n",
    "            \n",
    "        elif annotation['labels'][idx] == 3 :\n",
    "        \n",
    "            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='orange',facecolor='none')\n",
    "        else:\n",
    "            rect = patches.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),linewidth=1,edgecolor='r',facecolor='none')\n",
    "\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3732c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class simpleDataset(object):\n",
    "\n",
    "\n",
    "    def __init__(self, dataset,resize,color, img_foler_path,transforms=None):\n",
    "    #             self.root = root\n",
    "            self.transforms = transforms\n",
    "            self.adnoc = dataset\n",
    "            self.ids = dataset.index\n",
    "            self. filenames=dataset['path'].to_list()\n",
    "            self.resize =resize\n",
    "            self.color=color\n",
    "            self.img_foler_path=img_foler_path\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        # Own coco file\n",
    "        adnoc_df = self.adnoc\n",
    "        # Image ID ,폴더에서 index번째 \n",
    "        img_id = self.ids[index]\n",
    "\n",
    "       # List: get annotation id from coco, index번째 annotation가져오기 [[1,2,3,4],[5,6,7,8]]\n",
    "        annotation = adnoc_df['box'][img_id]\n",
    "\n",
    "\n",
    "        # open the input image, 흑백=L , 단색=1\n",
    "        img= Image.open(str(self.img_foler_path)+str(adnoc_df.loc[img_id]['path'])).convert(self.color)\n",
    "        img= img.resize((int(img.width / self.resize), int(img.height / self.resize)))\n",
    "      \n",
    "        # number of objects in the image\n",
    "        num_objs = len(annotation)\n",
    "\n",
    "        # Bounding boxes for objects\n",
    "        # In coco format, bbox = [xmin, ymin, width, height]\n",
    "        # In pytorch, the input should be [xmin, ymin, xmax, ymax]\n",
    "        boxes = []\n",
    "        areas = []\n",
    "        label = []\n",
    "        for i in range(num_objs):\n",
    "\n",
    "            xmin = annotation[i][0]\n",
    "            ymin = annotation[i][1]\n",
    "            xmax = xmin + annotation[i][2]\n",
    "            ymax = ymin + annotation[i][3]\n",
    "            l=annotation[i][4]\n",
    "            area=annotation[i][2]*annotation[i][3]\n",
    "\n",
    "            boxes.append([xmin/self.resize, ymin/self.resize, xmax/self.resize, ymax/self.resize])\n",
    "          \n",
    "            label.append(l)\n",
    "            areas.append(area)\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        #areas= box size = width * height\n",
    "        areas = torch.as_tensor(areas, dtype=torch.float32)\n",
    "\n",
    "        # Labels (In my case, I only one class: target class or background)\n",
    "        labels = torch.as_tensor(label, dtype=torch.int64)\n",
    "\n",
    "        # Tensorise img_id\n",
    "        img_id = torch.tensor([img_id])\n",
    "\n",
    "        # Iscrowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        # Annotation is in dictionary format\n",
    "        my_annotation = {}\n",
    "        my_annotation[\"boxes\"] = boxes\n",
    "        my_annotation[\"labels\"] = labels\n",
    "        my_annotation[\"image_id\"] = img_id\n",
    "        my_annotation[\"area\"] = areas\n",
    "        my_annotation[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, my_annotation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "\n",
    "\n",
    "    # the total number of samples (optional)\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31ccc9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_RPA(test_data_loader,model,param,iteration):\n",
    "    \n",
    "    model = get_model_instance_segmentation(4,5)\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(param))\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    confi=[0.5]\n",
    "    RECALL=[]\n",
    "    PRECISION=[]\n",
    "    F1_SCORE=[]\n",
    "    MEAN_R=[]\n",
    "    MEAN_P=[]\n",
    "    MEAN_F1=[]\n",
    "    \n",
    "    for c in confi: \n",
    "        labels = []\n",
    "        preds_adj_all = []\n",
    "        annot_all = []\n",
    "        print('confidence=',c)\n",
    "        for im, annot in tqdm(test_data_loader, position = 0, leave = True):\n",
    "            im = list(img.to(device) for img in im)\n",
    "\n",
    "   \n",
    "            for t in annot:\n",
    "                labels += t['labels']\n",
    "\n",
    "            with torch.no_grad():\n",
    "                preds_adj = make_prediction(model, im, c)\n",
    "                preds_adj = [{k: v.to(torch.device('cpu')) for k, v in t.items()} for t in preds_adj]\n",
    "                preds_adj_all.append(preds_adj)\n",
    "                annot_all.append(annot)\n",
    "\n",
    "        #precision=0.2\n",
    "        iou_threds=0.5\n",
    "        pr_f1=rp_f1.Precision_Recall_F1(iou_threds,preds_adj_all,annot_all)\n",
    "      \n",
    "        \n",
    "        recall,mean_r=pr_f1.RECALL()\n",
    "        precision,mean_p=pr_f1.PRECISION()\n",
    "        f1_score,mean_f1=pr_f1.F1_SCORE()\n",
    "      \n",
    "\n",
    "        RECALL.append(recall)\n",
    "        PRECISION.append(precision)\n",
    "        F1_SCORE.append(f1_score)\n",
    "        MEAN_R.append(mean_r)\n",
    "        MEAN_P.append(mean_p)\n",
    "        MEAN_F1.append(mean_f1)\n",
    "        \n",
    "    print(MEAN_R,'\\n',MEAN_P,'\\n',MEAN_F1)\n",
    "    result=pd.DataFrame(confi,columns=['confidence'])\n",
    "    result['iteration']=iteration\n",
    "    result['recall']=[RECALL]\n",
    "    result['mean_recall']=MEAN_R\n",
    "    result['precision']=[PRECISION]\n",
    "    result['mean_precision']=MEAN_P\n",
    "    result['f1_form']=[F1_SCORE]\n",
    "    result['mean_f1']=MEAN_F1\n",
    "      \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "862ae8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(train,batch):\n",
    "   \n",
    "    sampled=train.sample(n=batch,random_state=42)\n",
    "    train_rest=train.drop(sampled.index)\n",
    "        \n",
    "    sample_dataset = simpleDataset(dataset=sampled,\n",
    "                                  resize=4,\n",
    "                                  color='L',\n",
    "                                  img_foler_path='D:/OBJ_PAPER/itb_p_500/',\n",
    "                                  transforms=get_transform())\n",
    "    \n",
    "    sample_data_loader = torch.utils.data.DataLoader(sample_dataset,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=0,\n",
    "                                              collate_fn=collate_fn)\n",
    "    return sampled,train_rest,sample_data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41e961dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load():\n",
    "    \n",
    "    file_path='D:/OBJ_PAPER/'\n",
    "    itb=pd.read_pickle(file_path+'itb.pkl')\n",
    "\n",
    "    test=itb.sample(frac=0.2,random_state=42)\n",
    "    train_valid=itb.drop(test.index)\n",
    "    valid=train_valid.sample(n=50, random_state=42)\n",
    "    train=train_valid.drop(valid.index)\n",
    "\n",
    "\n",
    "    test.reset_index(drop=True,inplace=True)\n",
    "    test['index']=test.index\n",
    "\n",
    "    valid.reset_index(drop=True,inplace=True)\n",
    "    valid['index']=valid.index\n",
    "\n",
    "    train.reset_index(drop=True,inplace=True)\n",
    "    train['index']=train.index\n",
    "    print(' train shape : ',train.shape, 'valid shape : ', valid.shape, 'test shape : ', test.shape, )\n",
    "\n",
    "    # create own Dataset\n",
    "    train_dataset = simpleDataset(dataset=train,\n",
    "                                  resize=4,\n",
    "                                  color='L',\n",
    "                                  img_foler_path=file_path+'Data/itb_p_500/',\n",
    "                                  transforms=get_transform())\n",
    "\n",
    "    valid_dataset = simpleDataset(\n",
    "                              dataset=valid,\n",
    "                              resize=4,\n",
    "                              color='L',\n",
    "                              img_foler_path=file_path+'Data/itb_p_500/',\n",
    "                              transforms=get_transform())\n",
    "\n",
    "    test_dataset = simpleDataset(\n",
    "                              dataset=test,\n",
    "                              resize=4,\n",
    "                              color='L',\n",
    "                              img_foler_path=file_path+'Data/itb_p_500/',\n",
    "                              transforms=get_transform())\n",
    "\n",
    "\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=0,                                         \n",
    "                                              collate_fn=collate_fn)\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=0,\n",
    "                                              collate_fn=collate_fn)\n",
    "\n",
    "    test_data_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=0,\n",
    "                                          collate_fn=collate_fn)\n",
    "\n",
    "    return test,valid,train,train_data_loader,valid_data_loader, test_data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4542f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(data):\n",
    " \n",
    "    # create own Dataset\n",
    "    dataset = simpleDataset(dataset=data,\n",
    "                                  resize=4,\n",
    "                                  color='L',\n",
    "                                  img_foler_path='D:/OBJ_PAPER/Data/itb_p_500/',\n",
    "                                  transforms=get_transform())\n",
    "\n",
    "\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=0,\n",
    "                                          collate_fn=collate_fn)\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a80ff11",
   "metadata": {},
   "source": [
    "# Uncertianty samplig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc449063",
   "metadata": {},
   "source": [
    "### 불확실성이 큰것 top-k 개 샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a7f7ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class uncertainty_sampling:\n",
    "    '''\n",
    "    'uncertainty', : a\n",
    "     'class_difficulty', : b\n",
    "     'class_ambiguity',: c\n",
    "        'class_sparse', x\n",
    "     'al_score'\n",
    "    '''\n",
    "    def __init__(self,model,confidence,batch,train_data_loader,method,param):\n",
    "        \n",
    "        \n",
    "        self.model=model\n",
    "        self.confidence=confidence\n",
    "        self.batch=batch\n",
    "        self.train_data_loader=train_data_loader\n",
    "        self.method=method\n",
    "        self.a=param[0]\n",
    "        self.b=param[1]\n",
    "        self.c=param[2]\n",
    "        \n",
    "    def bbox_iou(self,box1, box2, x1y1x2y2=True):\n",
    "        \"\"\"\n",
    "        Returns the IoU of two bounding boxes\n",
    "        \"\"\"\n",
    "        box1=torch.tensor(box1)\n",
    "        box2=torch.tensor(box2)\n",
    "\n",
    "        if not x1y1x2y2:\n",
    "            # Transform from center and width to exact coordinates\n",
    "            b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n",
    "            b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n",
    "            b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n",
    "            b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\n",
    "        else:\n",
    "            # Get the coordinates of bounding boxes\n",
    "            b1_x1, b1_y1, b1_x2, b1_y2 = box1[0], box1[1], box1[2], box1[3]\n",
    "            b2_x1, b2_y1, b2_x2, b2_y2 = box2[0], box2[1], box2[2], box2[3]\n",
    "\n",
    "        # get the corrdinates of the intersection rectangle\n",
    "        inter_rect_x1 = torch.max(b1_x1, b2_x1)\n",
    "        inter_rect_y1 = torch.max(b1_y1, b2_y1)\n",
    "        inter_rect_x2 = torch.min(b1_x2, b2_x2)\n",
    "        inter_rect_y2 = torch.min(b1_y2, b2_y2)\n",
    "        # Intersection area\n",
    "        inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * torch.clamp(inter_rect_y2 - inter_rect_y1 + 1, min=0)\n",
    "        # Union Area\n",
    "        b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n",
    "        b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n",
    "\n",
    "        iou = inter_area / (b1_area + b2_area - inter_area + 1e-16)\n",
    "\n",
    "        return iou\n",
    "\n",
    "    def img_uncertainty(self,model,ascend):\n",
    "        '''\n",
    "        내림차순, 큰 수 부터\n",
    "        ascend=False\n",
    "        오름차순, 작은 수 부터\n",
    "        ascend=True \n",
    "        \n",
    "        '''\n",
    "        img_id=[]\n",
    "        pred_label=[]\n",
    "        pred_scores=[]\n",
    "        labels = []\n",
    "        bbox=[]\n",
    "        img_uncertianty=[]\n",
    "        \n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        model.to(device)\n",
    "        \n",
    "        for im, annot in tqdm(self.train_data_loader, position = 0, leave = True):\n",
    "            im = list(img.to(device) for img in im)\n",
    "            #test data 이미지 id 저장\n",
    "            img_id.append(annot[0]['image_id'].item())\n",
    "\n",
    "            for t in annot:\n",
    "                labels += t['labels']\n",
    "\n",
    "            with torch.no_grad():\n",
    "                preds_adj = make_prediction(model, im, self.confidence)\n",
    "                preds_adj = [{k: v.to(torch.device('cpu')) for k, v in t.items()} for t in preds_adj]\n",
    "\n",
    "                #예측 label 저장\n",
    "                pred_label.append(preds_adj[0]['labels'].tolist())\n",
    "                #box\n",
    "                bbox.append((preds_adj[0]['boxes'].tolist()))\n",
    "                #예측 score 저장\n",
    "                pred_scores.append(preds_adj[0]['scores'].tolist())\n",
    "                img_uncertianty.append(np.mean(preds_adj[0]['scores'].tolist()))\n",
    "\n",
    "        model_pred=pd.DataFrame(img_id,columns=['img_id'])\n",
    "        model_pred['label']=pred_label\n",
    "        model_pred['score']=pred_scores\n",
    "        model_pred['bbox']=bbox\n",
    "        #confidence가 0.5이상인 객체의 score 합\n",
    "        uncertainty=[]\n",
    "        for i in range(len(model_pred)):\n",
    "\n",
    "            scores=model_pred.iloc[i]['score']\n",
    "            un=0\n",
    "            for s in scores:\n",
    "\n",
    "                if s>self.a:\n",
    "                    un=un+s\n",
    "            uncertainty.append(un)\n",
    "\n",
    "        model_pred['uncertainty']=uncertainty\n",
    "        \n",
    "        #confidence가 0.3이하인 객체의 개수\n",
    "        class_difficulty=[]\n",
    "        for i in range(len(model_pred)):\n",
    "            cls_dif=0\n",
    "            scores=model_pred.iloc[i]['score']\n",
    "            for s in scores:\n",
    "                if s<self.b:\n",
    "                    cls_dif+=1\n",
    "            class_difficulty.append(cls_dif)\n",
    "\n",
    "        model_pred['class_difficulty']=class_difficulty\n",
    "        \n",
    "        #iou 계산하여 클래스가 다르면서 중첩인 box개수\n",
    "        class_ambiguity=[]\n",
    "        for a in range(len(model_pred)):\n",
    "            box_index=list(range(len(model_pred.iloc[a]['bbox'])))\n",
    "            label_index=list(range(len(model_pred.iloc[a]['label'])))\n",
    "            iou_index=list(combinations(box_index, 2))\n",
    "\n",
    "            cls_amb=0\n",
    "            for i in iou_index:\n",
    "                box1_i=i[0]\n",
    "                box2_i=i[1]\n",
    "\n",
    "                #box좌표\n",
    "                box1=model_pred.iloc[a]['bbox'][box1_i]\n",
    "                box2=model_pred.iloc[a]['bbox'][box2_i]\n",
    "\n",
    "                #라벨\n",
    "                box1_label=model_pred.iloc[a]['label'][box1_i]\n",
    "                box2_label=model_pred.iloc[a]['label'][box2_i]\n",
    "\n",
    "                #class가 다른 경우\n",
    "\n",
    "                if (box1_label!= box2_label):\n",
    "                    #iou 계산\n",
    "                    iou=self.bbox_iou(box1, box2, x1y1x2y2=True)\n",
    "                    if iou>self.c:\n",
    "                        cls_amb+=1\n",
    "            class_ambiguity.append(cls_amb)        \n",
    "                #클래스가 같은경우\n",
    "\n",
    "        model_pred['class_ambiguity']=class_ambiguity\n",
    "        \n",
    "        #class sparse, 예측된 라벨 중 특정 라벨의 수가 적은 경우 해당 라벨을 우선적으로 선택\n",
    "        text=0\n",
    "        form=0\n",
    "        table=0\n",
    "\n",
    "        for i in range(len(model_pred)):\n",
    "\n",
    "            label_line=model_pred['label'].iloc[i]\n",
    "            for l in label_line:\n",
    "                if l==1:\n",
    "                    form+=1\n",
    "\n",
    "                elif l==2:\n",
    "                    table+=1\n",
    "\n",
    "                else:\n",
    "                    text+=1\n",
    "\n",
    "\n",
    "        total=text+form+table\n",
    "        text_ratio=round(text/total,5)\n",
    "        form_ratio=round(form/total,5)\n",
    "        table_ratio=round(table/total,5)\n",
    "        tt=[text_ratio,form_ratio,table_ratio]\n",
    "        total_ratio=pd.DataFrame(tt,columns=['label'])\n",
    "        total_ratio.index=['text_spars','form_spars','table_spars']\n",
    "        #비율이 가장 낮은 label\n",
    "        spars=total_ratio.sort_values(by=['label'],ascending=True).index[0]\n",
    "\n",
    "\n",
    "\n",
    "        text_spars=[]\n",
    "        form_spars=[]\n",
    "        table_spars=[]\n",
    "\n",
    "        for i in range(len(model_pred)):\n",
    "\n",
    "            img_text=0\n",
    "            img_form=0\n",
    "            img_table=0\n",
    "\n",
    "            label_line=model_pred['label'].iloc[i]\n",
    "            for l in label_line:\n",
    "                if l==1:\n",
    "                    img_form+=1\n",
    "                elif l==2:\n",
    "                    img_table+=1\n",
    "                else:\n",
    "                    img_text+=1\n",
    "\n",
    "            text_spars.append(img_text*text_ratio)\n",
    "            form_spars.append(img_form*form_ratio)\n",
    "            table_spars.append(img_table*table_ratio)\n",
    "\n",
    "        model_pred['text_spars']=text_spars\n",
    "        model_pred['form_spars']=form_spars\n",
    "        model_pred['table_spars']=table_spars\n",
    "        \n",
    "        model_pred['class_sparse']=model_pred[spars]\n",
    "        model_pred['al_score']=model_pred[spars]+model_pred['uncertainty']+model_pred['class_difficulty']+model_pred['class_ambiguity']\n",
    "        model_pred.sort_values(by=[self.method],ascending=False,inplace=True)\n",
    "             \n",
    "        \n",
    "        return model_pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def sampling(self,train,ascend):\n",
    "        \n",
    "\n",
    "        model_pred=self.img_uncertainty(self.model,ascend)\n",
    "        sample_idx=model_pred[:self.batch]['img_id'].tolist()\n",
    "        sample=train.loc[sample_idx]\n",
    "        train_rest=train.drop(sample.index)\n",
    "        train_rest_dataset = simpleDataset(dataset=train_rest,\n",
    "                              resize=4,\n",
    "                              color='L',\n",
    "                              img_foler_path='D:/OBJ_PAPER/Data/itb_p_500/',\n",
    "                              transforms=get_transform())\n",
    "\n",
    "        train_rest_data_loader = torch.utils.data.DataLoader(train_rest_dataset,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=0,\n",
    "                                              collate_fn=collate_fn)\n",
    "\n",
    "        sample_dataset = simpleDataset(dataset=sample,\n",
    "                                  resize=4,\n",
    "                                  color='L',\n",
    "                                  img_foler_path='D:/OBJ_PAPER/Data/itb_p_500/',\n",
    "                                  transforms=get_transform())\n",
    "\n",
    "        sample_data_loader = torch.utils.data.DataLoader(sample_dataset,\n",
    "                                              batch_size=1,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=0,\n",
    "                                              collate_fn=collate_fn)\n",
    "\n",
    "      \n",
    "        \n",
    "        return model_pred,sample,train_rest,train_rest_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "fccb9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Total=[100,200,300,343]\n",
    "Batch=30\n",
    "train=train1\n",
    "valid=valid1\n",
    "test=test\n",
    "Train_param_path='D:/OBJ_PAPER/model_param/FRCN_itb_random1_batch30_total{}_param.pt'\n",
    "RESULT_path='D:/OBJ_PAPER/result/FRCN_random1_b30_total_{}_validation_p{}.csv'\n",
    "Sampled_img_path='D:/OBJ_PAPER/result/FRCN_random1_b30_total_{}_validation_p{}_sampled.csv'\n",
    "\n",
    "TL_train_Random(Total,Batch,train,valid,test,Train_param_path,RESULT_path,Sampled_img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aff4f3",
   "metadata": {},
   "source": [
    "# Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72e8ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='D:/OBJ_PAPER/Data/3_fold_cv/'\n",
    "\n",
    "train1=pd.read_pickle(data_path+'train1.pkl')\n",
    "train2=pd.read_pickle(data_path+'train2.pkl')\n",
    "train3=pd.read_pickle(data_path+'train3.pkl')\n",
    "\n",
    "valid1=pd.read_pickle(data_path+'valid1.pkl')\n",
    "valid2=pd.read_pickle(data_path+'valid2.pkl')\n",
    "valid3=pd.read_pickle(data_path+'valid3.pkl')\n",
    "\n",
    "test=pd.read_pickle(data_path+'test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79513aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_AL(train,valid,test,total,method,method_param,param_name,TL_param,Train_param_path,result_path,sample_path):  \n",
    "       \n",
    "    num_classes = 4\n",
    "    num_epochs = 100\n",
    "    train_layer=5\n",
    "    batch=30\n",
    "    patience=10\n",
    "    ascend=False\n",
    "    \n",
    "    model = get_model_instance_segmentation(num_classes,train_layer)\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "    # move model to the right device\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(TL_param))\n",
    "\n",
    "    # parameters\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.Adam(params, lr=0.0001)\n",
    "    \n",
    "    iteration = 0    \n",
    "\n",
    "    RESULT=pd.DataFrame()\n",
    "    Sampled_img=pd.DataFrame()\n",
    "    \n",
    "    #모델 저장 \n",
    "    train_param_path=Train_param_path.format(total,method,param_name)\n",
    "    \n",
    "    #data reload\n",
    "   \n",
    "    train_data_loader=data_load(train)\n",
    "    valid_data_loader=data_load(valid)\n",
    "    test_data_loader=data_load(test)\n",
    "    \n",
    "    while len(Sampled_img)<total:\n",
    "\n",
    "        if len(Sampled_img)+batch>total:\n",
    "            batch=(len(Sampled_img)+batch)-total\n",
    "            sample=train.sample(n=batch)\n",
    "            Sampled_img=Sampled_img.append(sample,ignore_index=True)\n",
    "            sample_data_loader=data_load(Sampled_img)\n",
    "            \n",
    "        else:\n",
    "            us=uncertainty_sampling(model,0.00001,batch,train_data_loader,method,method_param)\n",
    "\n",
    "            model_pred,sampled,train_rest,train_rest_data_loader=us.sampling(train,ascend)\n",
    "\n",
    "            Sampled_img=Sampled_img.append(sampled,ignore_index=True)  \n",
    "            sample_data_loader=data_load(Sampled_img)\n",
    "            \n",
    "            #sample 제외한 나머지 train 데이터\n",
    "            train=train_rest\n",
    "\n",
    "            #ranodm으로 가져온 N개 데이터\n",
    "            train_data_loader=train_rest_data_loader\n",
    "\n",
    "\n",
    "        iteration += 1\n",
    "        print(iteration)\n",
    "        model.train()\n",
    "        not_save_count=0\n",
    "        \n",
    "        #평균 loss\n",
    "        avg_train_loss=[]\n",
    "        avg_valid_loss=[]\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            # 모델이 학습되는 동안 trainning loss를 track\n",
    "            train_losses = []\n",
    "            # 모델이 학습되는 동안 validation loss를 track\n",
    "            valid_losses = []\n",
    "            \n",
    "            st = time.time()\n",
    "            for imgs, annotations in sample_data_loader:\n",
    "\n",
    "                imgs = list(img.to(device) for img in imgs)\n",
    "                annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
    "                loss_dict = model(imgs, annotations)\n",
    "                #batch size=10, 10개 loss 각각 도출\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "                train_losses.append(losses.item())       \n",
    "                optimizer.zero_grad()\n",
    "                losses.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            #이미지 한장당 평균 loss\n",
    "            avg_train_loss.append(np.mean(train_losses).round(5))\n",
    "\n",
    "            #validation, early_stop, save weights\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for im, annot in valid_data_loader:\n",
    "                    im = list(img.to(device) for img in im)\n",
    "                    annot = [{k: v.to(device) for k, v in t.items()} for t in annot]\n",
    "                    val_loss_dict = model(im, annot)\n",
    "                    val_losses = sum(val_loss for val_loss in val_loss_dict.values())\n",
    "                    valid_losses.append(val_losses.item())\n",
    "\n",
    "                epoch_val_loss=np.mean(valid_losses).round(5)\n",
    "                avg_valid_loss.append(epoch_val_loss)  \n",
    "\n",
    "            fi = time.time()     \n",
    "            print('epoch:',epoch,'train_loss: ',np.mean(train_losses).round(5),'validation loss : ',np.mean(valid_losses).round(5),'time',fi-st)\n",
    "\n",
    "\n",
    "            min_val_loss=np.min(avg_valid_loss)\n",
    "            if min_val_loss>=epoch_val_loss:\n",
    "\n",
    "                torch.save(model.state_dict(),train_param_path)\n",
    "                not_save_count=0\n",
    "                print('epoch:',epoch,'save model')\n",
    "\n",
    "            else:\n",
    "                not_save_count+=1\n",
    "                model.load_state_dict(torch.load(train_param_path))\n",
    "                if not_save_count>=patience:\n",
    "                    print('no more training')\n",
    "                    break\n",
    "\n",
    "\n",
    "        fi = time.time()     \n",
    "        print('iteration:',iteration,'train_loss: ',np.mean(train_losses).round(5),'time',fi-st)\n",
    "        print('sample num:',len(Sampled_img))\n",
    "        model.load_state_dict(torch.load(train_param_path))\n",
    "\n",
    "        result_batch=result_RPA(test_data_loader,model,train_param_path,iteration)\n",
    "        RESULT=RESULT.append(result_batch,ignore_index=True)\n",
    "\n",
    "    RESULT.to_csv(result_path.format(total,method,param_name),index=False)   \n",
    "    Sampled_img.to_csv(sample_path.format(total,method,param_name),index=False) \n",
    "    return RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d34fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 180 method: class_difficulty b_param: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 348/348 [00:29<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "epoch: 0 train_loss:  0.42246 validation loss :  0.22442 time 9.256716966629028\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.24724 validation loss :  0.1872 time 9.180119752883911\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.17198 validation loss :  0.19799 time 9.214881420135498\n",
      "epoch: 3 train_loss:  0.16481 validation loss :  0.22946 time 9.20757508277893\n",
      "epoch: 4 train_loss:  0.16839 validation loss :  0.2043 time 9.246517419815063\n",
      "epoch: 5 train_loss:  0.16776 validation loss :  0.2378 time 9.23314619064331\n",
      "epoch: 6 train_loss:  0.16321 validation loss :  0.21004 time 9.228680849075317\n",
      "epoch: 7 train_loss:  0.16565 validation loss :  0.23407 time 9.34303331375122\n",
      "epoch: 8 train_loss:  0.16757 validation loss :  0.22818 time 9.23823356628418\n",
      "epoch: 9 train_loss:  0.17963 validation loss :  0.19368 time 9.273492097854614\n",
      "epoch: 10 train_loss:  0.17901 validation loss :  0.21327 time 9.253748655319214\n",
      "epoch: 11 train_loss:  0.17281 validation loss :  0.21638 time 9.25045132637024\n",
      "no more training\n",
      "iteration: 1 train_loss:  0.17281 time 9.389607191085815\n",
      "sample num: 30\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.39785, 0.89873, 0.6484]\n",
      "recall [0.69811, 0.98611, 0.91026]\n",
      "[0.86483] \n",
      " [0.64833] \n",
      " [0.7410917998096697]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 318/318 [00:26<00:00, 11.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "epoch: 0 train_loss:  0.25846 validation loss :  0.19507 time 14.291904211044312\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.21388 validation loss :  0.17197 time 14.255435705184937\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.16252 validation loss :  0.17681 time 14.445155620574951\n",
      "epoch: 3 train_loss:  0.15682 validation loss :  0.16926 time 14.861735105514526\n",
      "epoch: 3 save model\n",
      "epoch: 4 train_loss:  0.14266 validation loss :  0.18507 time 14.70559549331665\n",
      "epoch: 5 train_loss:  0.14098 validation loss :  0.16413 time 14.532912015914917\n",
      "epoch: 5 save model\n",
      "epoch: 6 train_loss:  0.13641 validation loss :  0.14308 time 14.719090461730957\n",
      "epoch: 6 save model\n",
      "epoch: 7 train_loss:  0.1273 validation loss :  0.16247 time 14.890436887741089\n",
      "epoch: 8 train_loss:  0.12391 validation loss :  0.15093 time 14.812377452850342\n",
      "epoch: 9 train_loss:  0.12334 validation loss :  0.15681 time 14.802811622619629\n",
      "epoch: 10 train_loss:  0.12285 validation loss :  0.16362 time 14.688991069793701\n",
      "epoch: 11 train_loss:  0.12476 validation loss :  0.15658 time 14.585084199905396\n",
      "epoch: 12 train_loss:  0.12161 validation loss :  0.14832 time 14.86854887008667\n",
      "epoch: 13 train_loss:  0.11905 validation loss :  0.16845 time 14.572649478912354\n",
      "epoch: 14 train_loss:  0.12385 validation loss :  0.14759 time 14.712289571762085\n",
      "epoch: 15 train_loss:  0.12294 validation loss :  0.16568 time 14.743801832199097\n",
      "epoch: 16 train_loss:  0.12467 validation loss :  0.14557 time 14.669134140014648\n",
      "no more training\n",
      "iteration: 2 train_loss:  0.12467 time 14.817761659622192\n",
      "sample num: 60\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.59494, 0.92208, 0.66667]\n",
      "recall [0.88679, 0.98611, 0.94872]\n",
      "[0.94054] \n",
      " [0.7279] \n",
      " [0.8206696866534007]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 288/288 [00:25<00:00, 11.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "epoch: 0 train_loss:  0.23367 validation loss :  0.27694 time 20.111791133880615\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.26378 validation loss :  0.20823 time 19.746585369110107\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.20075 validation loss :  0.16168 time 19.409484386444092\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.16174 validation loss :  0.1402 time 19.677744388580322\n",
      "epoch: 3 save model\n",
      "epoch: 4 train_loss:  0.13622 validation loss :  0.13299 time 19.690001964569092\n",
      "epoch: 4 save model\n",
      "epoch: 5 train_loss:  0.118 validation loss :  0.1385 time 19.688225269317627\n",
      "epoch: 6 train_loss:  0.11887 validation loss :  0.14144 time 20.16241979598999\n",
      "epoch: 7 train_loss:  0.11908 validation loss :  0.13886 time 20.116767406463623\n",
      "epoch: 8 train_loss:  0.12037 validation loss :  0.1393 time 19.72739815711975\n",
      "epoch: 9 train_loss:  0.11553 validation loss :  0.13666 time 19.62159013748169\n",
      "epoch: 10 train_loss:  0.11655 validation loss :  0.13915 time 19.5272114276886\n",
      "epoch: 11 train_loss:  0.11701 validation loss :  0.1485 time 19.758641481399536\n",
      "epoch: 12 train_loss:  0.12736 validation loss :  0.14391 time 19.790249824523926\n",
      "epoch: 13 train_loss:  0.12473 validation loss :  0.14622 time 19.580421924591064\n",
      "epoch: 14 train_loss:  0.12271 validation loss :  0.14343 time 19.652360200881958\n",
      "no more training\n",
      "iteration: 3 train_loss:  0.12271 time 19.796183347702026\n",
      "sample num: 90\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.71429, 0.93421, 0.72549]\n",
      "recall [0.84906, 0.98611, 0.94872]\n",
      "[0.92796] \n",
      " [0.79133] \n",
      " [0.8542160854771444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 258/258 [00:22<00:00, 11.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "epoch: 0 train_loss:  0.16913 validation loss :  0.25286 time 25.2662992477417\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.19789 validation loss :  0.16624 time 25.247189044952393\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.14863 validation loss :  0.13502 time 25.54863142967224\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.12689 validation loss :  0.13685 time 25.298964977264404\n",
      "epoch: 4 train_loss:  0.12205 validation loss :  0.14858 time 25.30047345161438\n",
      "epoch: 5 train_loss:  0.12968 validation loss :  0.1484 time 25.293200969696045\n",
      "epoch: 6 train_loss:  0.1231 validation loss :  0.1464 time 25.23583149909973\n",
      "epoch: 7 train_loss:  0.13737 validation loss :  0.15367 time 25.278066873550415\n",
      "epoch: 8 train_loss:  0.12591 validation loss :  0.14102 time 24.892439603805542\n",
      "epoch: 9 train_loss:  0.12122 validation loss :  0.14992 time 24.816153287887573\n",
      "epoch: 10 train_loss:  0.12775 validation loss :  0.14179 time 24.821747064590454\n",
      "epoch: 11 train_loss:  0.12444 validation loss :  0.15496 time 24.89018487930298\n",
      "epoch: 12 train_loss:  0.12685 validation loss :  0.14234 time 24.97105646133423\n",
      "no more training\n",
      "iteration: 4 train_loss:  0.12685 time 25.112714529037476\n",
      "sample num: 120\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.65278, 0.91026, 0.64407]\n",
      "recall [0.88679, 0.98611, 0.97436]\n",
      "[0.94909] \n",
      " [0.7357] \n",
      " [0.82888135969468]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 228/228 [00:20<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "epoch: 0 train_loss:  0.1648 validation loss :  0.25423 time 29.675809860229492\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.187 validation loss :  0.15609 time 30.259945392608643\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.12755 validation loss :  0.13067 time 30.247909545898438\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.11046 validation loss :  0.13332 time 29.515095949172974\n",
      "epoch: 4 train_loss:  0.1123 validation loss :  0.129 time 29.773736476898193\n",
      "epoch: 4 save model\n",
      "epoch: 5 train_loss:  0.10566 validation loss :  0.12492 time 29.81142807006836\n",
      "epoch: 5 save model\n",
      "epoch: 6 train_loss:  0.09169 validation loss :  0.1321 time 29.45757293701172\n",
      "epoch: 7 train_loss:  0.09307 validation loss :  0.13812 time 29.524118900299072\n",
      "epoch: 8 train_loss:  0.0941 validation loss :  0.13995 time 29.53432559967041\n",
      "epoch: 9 train_loss:  0.09174 validation loss :  0.13007 time 29.530128002166748\n",
      "epoch: 10 train_loss:  0.09699 validation loss :  0.16497 time 29.481295108795166\n",
      "epoch: 11 train_loss:  0.09112 validation loss :  0.1405 time 29.482162475585938\n",
      "epoch: 12 train_loss:  0.09909 validation loss :  0.14149 time 29.975621700286865\n",
      "epoch: 13 train_loss:  0.09636 validation loss :  0.13189 time 29.771787405014038\n",
      "epoch: 14 train_loss:  0.09864 validation loss :  0.14691 time 30.15002942085266\n",
      "epoch: 15 train_loss:  0.09416 validation loss :  0.15057 time 29.584176301956177\n",
      "no more training\n",
      "iteration: 5 train_loss:  0.09416 time 29.727355003356934\n",
      "sample num: 150\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.88462, 0.94667, 0.69406]\n",
      "recall [0.86792, 0.98611, 0.97436]\n",
      "[0.9428] \n",
      " [0.84178] \n",
      " [0.8894307725066961]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 198/198 [00:17<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "epoch: 0 train_loss:  0.11137 validation loss :  0.23011 time 35.59016942977905\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.13079 validation loss :  0.16841 time 34.96989035606384\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.10308 validation loss :  0.15268 time 34.9290509223938\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.09804 validation loss :  0.15449 time 34.62121343612671\n",
      "epoch: 4 train_loss:  0.09634 validation loss :  0.14401 time 35.01569962501526\n",
      "epoch: 4 save model\n",
      "epoch: 5 train_loss:  0.10027 validation loss :  0.14234 time 34.6912145614624\n",
      "epoch: 5 save model\n",
      "epoch: 6 train_loss:  0.08888 validation loss :  0.14483 time 36.62220573425293\n",
      "epoch: 7 train_loss:  0.08984 validation loss :  0.16 time 34.595279693603516\n",
      "epoch: 8 train_loss:  0.09092 validation loss :  0.14633 time 34.999215602874756\n",
      "epoch: 9 train_loss:  0.09001 validation loss :  0.16186 time 34.92464065551758\n",
      "epoch: 10 train_loss:  0.09525 validation loss :  0.15146 time 34.94724416732788\n",
      "epoch: 11 train_loss:  0.08956 validation loss :  0.1376 time 34.743051528930664\n",
      "epoch: 11 save model\n",
      "epoch: 12 train_loss:  0.08653 validation loss :  0.16279 time 34.66145634651184\n",
      "epoch: 13 train_loss:  0.08256 validation loss :  0.17236 time 34.605372190475464\n",
      "epoch: 14 train_loss:  0.08153 validation loss :  0.16131 time 34.53692698478699\n",
      "epoch: 15 train_loss:  0.08445 validation loss :  0.15542 time 34.90030384063721\n",
      "epoch: 16 train_loss:  0.0815 validation loss :  0.15102 time 35.07780742645264\n",
      "epoch: 17 train_loss:  0.08533 validation loss :  0.16567 time 35.08139181137085\n",
      "epoch: 18 train_loss:  0.08385 validation loss :  0.14945 time 35.04578518867493\n",
      "epoch: 19 train_loss:  0.08356 validation loss :  0.15162 time 35.568843603134155\n",
      "epoch: 20 train_loss:  0.08437 validation loss :  0.14701 time 36.689162731170654\n",
      "epoch: 21 train_loss:  0.08508 validation loss :  0.15736 time 37.022578954696655\n",
      "no more training\n",
      "iteration: 6 train_loss:  0.08508 time 37.17509651184082\n",
      "sample num: 180\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.75806, 0.92208, 0.82778]\n",
      "recall [0.88679, 0.98611, 0.95513]\n",
      "[0.94268] \n",
      " [0.83597] \n",
      " [0.8861239699772299]\n",
      "total: 180 method: class_difficulty b_param: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 348/348 [00:32<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "epoch: 0 train_loss:  0.44994 validation loss :  0.23283 time 10.045851707458496\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.28001 validation loss :  0.20592 time 10.157382488250732\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.19722 validation loss :  0.20162 time 10.114675998687744\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.1579 validation loss :  0.20571 time 10.151305675506592\n",
      "epoch: 4 train_loss:  0.14479 validation loss :  0.21299 time 10.008137464523315\n",
      "epoch: 5 train_loss:  0.14621 validation loss :  0.20093 time 10.11502456665039\n",
      "epoch: 5 save model\n",
      "epoch: 6 train_loss:  0.16541 validation loss :  0.19958 time 10.124979972839355\n",
      "epoch: 6 save model\n",
      "epoch: 7 train_loss:  0.15436 validation loss :  0.20336 time 10.182618856430054\n",
      "epoch: 8 train_loss:  0.14505 validation loss :  0.19747 time 10.153548002243042\n",
      "epoch: 8 save model\n",
      "epoch: 9 train_loss:  0.14464 validation loss :  0.22198 time 10.16016960144043\n",
      "epoch: 10 train_loss:  0.13915 validation loss :  0.20853 time 10.206642389297485\n",
      "epoch: 11 train_loss:  0.13516 validation loss :  0.2022 time 10.234106540679932\n",
      "epoch: 12 train_loss:  0.13258 validation loss :  0.20576 time 9.72813868522644\n",
      "epoch: 13 train_loss:  0.13326 validation loss :  0.20887 time 9.563848733901978\n",
      "epoch: 14 train_loss:  0.13736 validation loss :  0.2007 time 9.700968027114868\n",
      "epoch: 15 train_loss:  0.13383 validation loss :  0.22124 time 9.547733306884766\n",
      "epoch: 16 train_loss:  0.13323 validation loss :  0.18924 time 9.506553649902344\n",
      "epoch: 16 save model\n",
      "epoch: 17 train_loss:  0.15004 validation loss :  0.19154 time 9.487825393676758\n",
      "epoch: 18 train_loss:  0.12196 validation loss :  0.18694 time 9.49970817565918\n",
      "epoch: 18 save model\n",
      "epoch: 19 train_loss:  0.12414 validation loss :  0.19954 time 9.522242546081543\n",
      "epoch: 20 train_loss:  0.11895 validation loss :  0.19977 time 9.58424687385559\n",
      "epoch: 21 train_loss:  0.11272 validation loss :  0.1877 time 9.614483833312988\n",
      "epoch: 22 train_loss:  0.1143 validation loss :  0.20605 time 9.77959656715393\n",
      "epoch: 23 train_loss:  0.11617 validation loss :  0.18876 time 9.650541067123413\n",
      "epoch: 24 train_loss:  0.11942 validation loss :  0.1934 time 9.615154266357422\n",
      "epoch: 25 train_loss:  0.11481 validation loss :  0.18971 time 9.508695602416992\n",
      "epoch: 26 train_loss:  0.11769 validation loss :  0.21528 time 9.514765501022339\n",
      "epoch: 27 train_loss:  0.11578 validation loss :  0.19194 time 9.510624408721924\n",
      "epoch: 28 train_loss:  0.12432 validation loss :  0.22038 time 9.550676107406616\n",
      "no more training\n",
      "iteration: 1 train_loss:  0.12432 time 9.695817232131958\n",
      "sample num: 30\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.38182, 0.89873, 0.48684]\n",
      "recall [0.79245, 0.98611, 0.94872]\n",
      "[0.90909] \n",
      " [0.58913] \n",
      " [0.7149446565924897]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 318/318 [00:27<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "epoch: 0 train_loss:  0.28914 validation loss :  0.29218 time 14.441341638565063\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.34414 validation loss :  0.15818 time 14.500022411346436\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.20537 validation loss :  0.17312 time 14.565520763397217\n",
      "epoch: 3 train_loss:  0.18939 validation loss :  0.18018 time 14.56230902671814\n",
      "epoch: 4 train_loss:  0.19404 validation loss :  0.15837 time 14.82620096206665\n",
      "epoch: 5 train_loss:  0.19243 validation loss :  0.19231 time 14.64518666267395\n",
      "epoch: 6 train_loss:  0.1976 validation loss :  0.16303 time 14.97433066368103\n",
      "epoch: 7 train_loss:  0.18947 validation loss :  0.17561 time 14.592803716659546\n",
      "epoch: 8 train_loss:  0.20453 validation loss :  0.16341 time 14.577155351638794\n",
      "epoch: 9 train_loss:  0.19082 validation loss :  0.17354 time 14.636354684829712\n",
      "epoch: 10 train_loss:  0.2008 validation loss :  0.1818 time 14.571927785873413\n",
      "epoch: 11 train_loss:  0.19031 validation loss :  0.15798 time 14.649170637130737\n",
      "epoch: 11 save model\n",
      "epoch: 12 train_loss:  0.15332 validation loss :  0.17709 time 14.513978242874146\n",
      "epoch: 13 train_loss:  0.15013 validation loss :  0.15612 time 14.691863775253296\n",
      "epoch: 13 save model\n",
      "epoch: 14 train_loss:  0.14723 validation loss :  0.15302 time 14.598411321640015\n",
      "epoch: 14 save model\n",
      "epoch: 15 train_loss:  0.13778 validation loss :  0.14848 time 14.50930380821228\n",
      "epoch: 15 save model\n",
      "epoch: 16 train_loss:  0.11994 validation loss :  0.14578 time 14.575746297836304\n",
      "epoch: 16 save model\n",
      "epoch: 17 train_loss:  0.1133 validation loss :  0.16318 time 14.533145666122437\n",
      "epoch: 18 train_loss:  0.1052 validation loss :  0.15243 time 14.585901260375977\n",
      "epoch: 19 train_loss:  0.10912 validation loss :  0.15244 time 14.593519926071167\n",
      "epoch: 20 train_loss:  0.10555 validation loss :  0.15688 time 14.697802305221558\n",
      "epoch: 21 train_loss:  0.10593 validation loss :  0.15649 time 14.698059320449829\n",
      "epoch: 22 train_loss:  0.1099 validation loss :  0.1625 time 14.644093990325928\n",
      "epoch: 23 train_loss:  0.11194 validation loss :  0.1505 time 14.538502931594849\n",
      "epoch: 24 train_loss:  0.10895 validation loss :  0.15907 time 14.565030574798584\n",
      "epoch: 25 train_loss:  0.11544 validation loss :  0.16848 time 14.83742380142212\n",
      "epoch: 26 train_loss:  0.1098 validation loss :  0.15522 time 14.738247871398926\n",
      "no more training\n",
      "iteration: 2 train_loss:  0.1098 time 14.877675294876099\n",
      "sample num: 60\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.5641, 0.89744, 0.735]\n",
      "recall [0.83019, 0.97222, 0.94231]\n",
      "[0.91491] \n",
      " [0.73218] \n",
      " [0.8134088650893394]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 288/288 [00:24<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "epoch: 0 train_loss:  0.18142 validation loss :  0.21152 time 19.9313862323761\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.21809 validation loss :  0.14314 time 19.790119886398315\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.15817 validation loss :  0.14122 time 19.687138319015503\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.12904 validation loss :  0.14099 time 19.85701894760132\n",
      "epoch: 3 save model\n",
      "epoch: 4 train_loss:  0.11785 validation loss :  0.14123 time 19.73690366744995\n",
      "epoch: 5 train_loss:  0.1188 validation loss :  0.13824 time 19.5014545917511\n",
      "epoch: 5 save model\n",
      "epoch: 6 train_loss:  0.10357 validation loss :  0.14356 time 20.03749680519104\n",
      "epoch: 7 train_loss:  0.10157 validation loss :  0.13665 time 19.529590845108032\n",
      "epoch: 7 save model\n",
      "epoch: 8 train_loss:  0.09423 validation loss :  0.13572 time 19.638765573501587\n",
      "epoch: 8 save model\n",
      "epoch: 9 train_loss:  0.08678 validation loss :  0.12542 time 19.505243062973022\n",
      "epoch: 9 save model\n",
      "epoch: 10 train_loss:  0.08929 validation loss :  0.13643 time 19.479554414749146\n",
      "epoch: 11 train_loss:  0.08529 validation loss :  0.13508 time 19.526843786239624\n",
      "epoch: 12 train_loss:  0.08638 validation loss :  0.13605 time 19.540268182754517\n",
      "epoch: 13 train_loss:  0.08593 validation loss :  0.13879 time 19.53968071937561\n",
      "epoch: 14 train_loss:  0.0889 validation loss :  0.13625 time 19.56991934776306\n",
      "epoch: 15 train_loss:  0.08405 validation loss :  0.128 time 19.568148136138916\n",
      "epoch: 16 train_loss:  0.09352 validation loss :  0.15322 time 19.495012521743774\n",
      "epoch: 17 train_loss:  0.08861 validation loss :  0.13633 time 19.503300666809082\n",
      "epoch: 18 train_loss:  0.08981 validation loss :  0.13964 time 19.69228982925415\n",
      "epoch: 19 train_loss:  0.08894 validation loss :  0.14145 time 19.527518272399902\n",
      "no more training\n",
      "iteration: 3 train_loss:  0.08894 time 19.665948629379272\n",
      "sample num: 90\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.75806, 0.92208, 0.84444]\n",
      "recall [0.88679, 0.98611, 0.97436]\n",
      "[0.94909] \n",
      " [0.84153] \n",
      " [0.8920795117892125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 258/258 [00:21<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "epoch: 0 train_loss:  0.13632 validation loss :  0.17621 time 24.42717981338501\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.16688 validation loss :  0.17601 time 24.52860140800476\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.13552 validation loss :  0.14386 time 24.42672085762024\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.12071 validation loss :  0.13874 time 25.245906591415405\n",
      "epoch: 3 save model\n",
      "epoch: 4 train_loss:  0.10938 validation loss :  0.13574 time 25.258990049362183\n",
      "epoch: 4 save model\n",
      "epoch: 5 train_loss:  0.08627 validation loss :  0.12196 time 24.738422870635986\n",
      "epoch: 5 save model\n",
      "epoch: 6 train_loss:  0.0867 validation loss :  0.14073 time 24.511282920837402\n",
      "epoch: 7 train_loss:  0.08468 validation loss :  0.1329 time 24.668538570404053\n",
      "epoch: 8 train_loss:  0.08345 validation loss :  0.13315 time 24.580973148345947\n",
      "epoch: 9 train_loss:  0.0855 validation loss :  0.13414 time 24.52765703201294\n",
      "epoch: 10 train_loss:  0.0857 validation loss :  0.13321 time 24.613888025283813\n",
      "epoch: 11 train_loss:  0.08277 validation loss :  0.15256 time 24.926448822021484\n",
      "epoch: 12 train_loss:  0.08524 validation loss :  0.13513 time 24.68892526626587\n",
      "epoch: 13 train_loss:  0.08575 validation loss :  0.13902 time 24.610029935836792\n",
      "epoch: 14 train_loss:  0.08762 validation loss :  0.14532 time 24.538185834884644\n",
      "epoch: 15 train_loss:  0.08554 validation loss :  0.14301 time 24.487356185913086\n",
      "no more training\n",
      "iteration: 4 train_loss:  0.08554 time 24.628345727920532\n",
      "sample num: 120\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.76923, 0.86585, 0.75862]\n",
      "recall [0.9434, 0.98611, 0.98718]\n",
      "[0.97223] \n",
      " [0.7979] \n",
      " [0.8764806166778711]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 228/228 [00:19<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "epoch: 0 train_loss:  0.11933 validation loss :  0.29971 time 29.773282766342163\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.24655 validation loss :  0.16037 time 29.66757822036743\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.1303 validation loss :  0.13752 time 29.486722230911255\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.09254 validation loss :  0.12191 time 29.630306243896484\n",
      "epoch: 3 save model\n",
      "epoch: 4 train_loss:  0.08427 validation loss :  0.11962 time 29.753573894500732\n",
      "epoch: 4 save model\n",
      "epoch: 5 train_loss:  0.07936 validation loss :  0.14092 time 29.88572120666504\n",
      "epoch: 6 train_loss:  0.08196 validation loss :  0.13151 time 30.1777503490448\n",
      "epoch: 7 train_loss:  0.07991 validation loss :  0.12911 time 30.298201084136963\n",
      "epoch: 8 train_loss:  0.07986 validation loss :  0.1302 time 30.09528946876526\n",
      "epoch: 9 train_loss:  0.08078 validation loss :  0.13073 time 29.86814522743225\n",
      "epoch: 10 train_loss:  0.07948 validation loss :  0.13745 time 29.978096961975098\n",
      "epoch: 11 train_loss:  0.08538 validation loss :  0.14559 time 29.585341930389404\n",
      "epoch: 12 train_loss:  0.08236 validation loss :  0.12865 time 29.810020923614502\n",
      "epoch: 13 train_loss:  0.08233 validation loss :  0.13206 time 29.87273859977722\n",
      "epoch: 14 train_loss:  0.08074 validation loss :  0.1306 time 29.612629652023315\n",
      "no more training\n",
      "iteration: 5 train_loss:  0.08074 time 29.764808177947998\n",
      "sample num: 150\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.86275, 0.9726, 0.77895]\n",
      "recall [0.83019, 0.98611, 0.94872]\n",
      "[0.92167] \n",
      " [0.87143] \n",
      " [0.895846174892644]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 198/198 [00:16<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "epoch: 0 train_loss:  0.08989 validation loss :  0.13513 time 34.56843972206116\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.09733 validation loss :  0.13909 time 34.81258702278137\n",
      "epoch: 2 train_loss:  0.0951 validation loss :  0.13415 time 34.721097469329834\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.08481 validation loss :  0.12177 time 34.813169717788696\n",
      "epoch: 3 save model\n",
      "epoch: 4 train_loss:  0.08154 validation loss :  0.12638 time 34.818033933639526\n",
      "epoch: 5 train_loss:  0.08019 validation loss :  0.12639 time 34.624021768569946\n",
      "epoch: 6 train_loss:  0.0756 validation loss :  0.13027 time 34.85856819152832\n",
      "epoch: 7 train_loss:  0.08037 validation loss :  0.12819 time 34.64772415161133\n",
      "epoch: 8 train_loss:  0.08104 validation loss :  0.1317 time 34.553497076034546\n",
      "epoch: 9 train_loss:  0.08002 validation loss :  0.13023 time 34.59896111488342\n",
      "epoch: 10 train_loss:  0.08033 validation loss :  0.13896 time 34.54239892959595\n",
      "epoch: 11 train_loss:  0.08009 validation loss :  0.13556 time 39.32905197143555\n",
      "epoch: 12 train_loss:  0.08173 validation loss :  0.14368 time 35.677526235580444\n",
      "epoch: 13 train_loss:  0.08299 validation loss :  0.13831 time 34.66093873977661\n",
      "no more training\n",
      "iteration: 6 train_loss:  0.08299 time 34.80953311920166\n",
      "sample num: 180\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.77586, 0.91026, 0.87059]\n",
      "recall [0.84906, 0.98611, 0.94872]\n",
      "[0.92796] \n",
      " [0.85224] \n",
      " [0.8884896420626894]\n",
      "total: 180 method: class_ambiguity c_param: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 348/348 [00:30<00:00, 11.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "epoch: 0 train_loss:  0.36054 validation loss :  0.24511 time 9.480547666549683\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.21581 validation loss :  0.24029 time 9.483786582946777\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.15235 validation loss :  0.24823 time 9.500691175460815\n",
      "epoch: 3 train_loss:  0.14075 validation loss :  0.25482 time 9.485244274139404\n",
      "epoch: 4 train_loss:  0.15936 validation loss :  0.25853 time 9.495850086212158\n",
      "epoch: 5 train_loss:  0.14508 validation loss :  0.26003 time 9.479269027709961\n",
      "epoch: 6 train_loss:  0.15618 validation loss :  0.25471 time 9.54671335220337\n",
      "epoch: 7 train_loss:  0.1518 validation loss :  0.25252 time 9.509220600128174\n",
      "epoch: 8 train_loss:  0.16296 validation loss :  0.2492 time 9.465083837509155\n",
      "epoch: 9 train_loss:  0.15593 validation loss :  0.24954 time 9.466178178787231\n",
      "epoch: 10 train_loss:  0.16117 validation loss :  0.26575 time 9.69372034072876\n",
      "epoch: 11 train_loss:  0.15236 validation loss :  0.27732 time 9.599778652191162\n",
      "no more training\n",
      "iteration: 1 train_loss:  0.15236 time 9.743951797485352\n",
      "sample num: 30\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.53846, 0.85542, 0.45246]\n",
      "recall [0.5283, 0.98611, 0.88462]\n",
      "[0.79968] \n",
      " [0.61545] \n",
      " [0.695572924042314]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 318/318 [00:27<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "epoch: 0 train_loss:  0.30633 validation loss :  0.26801 time 14.453686952590942\n",
      "epoch: 0 save model\n",
      "epoch: 1 train_loss:  0.2376 validation loss :  0.18075 time 14.472286462783813\n",
      "epoch: 1 save model\n",
      "epoch: 2 train_loss:  0.17783 validation loss :  0.17241 time 14.409119129180908\n",
      "epoch: 2 save model\n",
      "epoch: 3 train_loss:  0.1516 validation loss :  0.16833 time 14.576417922973633\n",
      "epoch: 3 save model\n",
      "epoch: 4 train_loss:  0.13331 validation loss :  0.16354 time 14.550203084945679\n",
      "epoch: 4 save model\n",
      "epoch: 5 train_loss:  0.11618 validation loss :  0.16938 time 14.44685697555542\n",
      "epoch: 6 train_loss:  0.10835 validation loss :  0.18224 time 14.452032327651978\n",
      "epoch: 7 train_loss:  0.1126 validation loss :  0.18315 time 14.452722072601318\n",
      "epoch: 8 train_loss:  0.10972 validation loss :  0.20035 time 14.466431617736816\n",
      "epoch: 9 train_loss:  0.11141 validation loss :  0.17986 time 14.498121738433838\n",
      "epoch: 10 train_loss:  0.10759 validation loss :  0.20523 time 14.625690460205078\n",
      "epoch: 11 train_loss:  0.113 validation loss :  0.18933 time 14.647340297698975\n",
      "epoch: 12 train_loss:  0.11248 validation loss :  0.19182 time 14.889379262924194\n",
      "epoch: 13 train_loss:  0.11377 validation loss :  0.1814 time 14.868221998214722\n",
      "epoch: 14 train_loss:  0.11202 validation loss :  0.19555 time 14.906632423400879\n",
      "no more training\n",
      "iteration: 2 train_loss:  0.11202 time 15.067604780197144\n",
      "sample num: 60\n",
      "confidence= 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision [0.73846, 0.9726, 0.68664]\n",
      "recall [0.90566, 0.98611, 0.95513]\n",
      "[0.94897] \n",
      " [0.79923] \n",
      " [0.8676870988445257]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 288/288 [00:25<00:00, 11.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "epoch: 0 train_loss:  0.243 validation loss :  0.28938 time 19.548088312149048\n",
      "epoch: 0 save model\n"
     ]
    }
   ],
   "source": [
    "TL_param='D:/OBJ_PAPER/model_param/model_fasterrcnn_bach5_p10_50_param.pt'\n",
    "Train_param_path='D:/OBJ_PAPER/model_param/FRCN_AL1_batch30_total{}_{}_{}param.pt'\n",
    "result_path='D:/OBJ_PAPER/result/FRCN_AL1_batch30_total{}_{}_{}_result.csv'\n",
    "sample_path='D:/OBJ_PAPER/result/FRCN_AL1_batch30_total{}_{}_{}_sampled.csv'\n",
    "\n",
    "\n",
    "train=train1\n",
    "valid=valid1\n",
    "test=test\n",
    "\n",
    "\n",
    "\n",
    "total=180\n",
    "Method= [\n",
    "     'class_difficulty',\n",
    "     'class_ambiguity',\n",
    "]\n",
    "\n",
    "a=[0.7,0.9]\n",
    "b=[0.1,0.5]\n",
    "c=[0.7,0.9]\n",
    "\n",
    "#param=[un_param,diff_param,ambi_param]\n",
    "\n",
    "for method in Method:\n",
    "    if method=='uncertainty':\n",
    "        for a_param in a:\n",
    "            print('total:',total,'method:',method,'a_param:',a_param)\n",
    "            method_param=[a_param,0.3,0.5]\n",
    "            train_AL(train,valid,test,total,method,method_param,a_param,TL_param,Train_param_path,result_path,sample_path)\n",
    "            \n",
    "    elif method=='class_difficulty':\n",
    "        for b_param in b:\n",
    "            print('total:',total,'method:',method,'b_param:',b_param)\n",
    "            method_param=[0.5,b_param,0.5]\n",
    "            train_AL(train,valid,test,total,method,method_param,b_param,TL_param,Train_param_path,result_path,sample_path)\n",
    "            \n",
    "    elif method=='class_ambiguity':\n",
    "        for c_param in c:\n",
    "            print('total:',total,'method:',method,'c_param:',c_param)\n",
    "            method_param=[0.5,0.3,c_param]\n",
    "            train_AL(train,valid,test,total,method,method_param,c_param,TL_param,Train_param_path,result_path,sample_path)         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
